{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85b9ec99-7477-4d02-9f59-2dba7cb9129b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/04 13:20:01 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------+----------+-------+--------+\n",
      "|             nome|        cidade|     marca| modelo|   preco|\n",
      "+-----------------+--------------+----------+-------+--------+\n",
      "|        Ana Silva|     São Paulo|    Toyota|Corolla| 75000.0|\n",
      "|        Ana Silva|     São Paulo|     Honda|  Civic| 72000.0|\n",
      "|      Bruno Souza|Rio de Janeiro|      Ford| Fiesta| 55000.0|\n",
      "|   Carlos Pereira|Belo Horizonte| Chevrolet|   Onix| 68000.0|\n",
      "|    Daniela Costa|      Curitiba|Volkswagen|   Golf| 90000.0|\n",
      "| Eduardo Oliveira|  Porto Alegre|   Renault|Sandero| 62000.0|\n",
      "|    Fernanda Lima|     Fortaleza|   Hyundai|   HB20| 69000.0|\n",
      "|   Gabriel Mendes| Florianópolis|    Nissan| Sentra| 83000.0|\n",
      "|   Helena Ribeiro|      Brasília|      Fiat|   Argo| 70000.0|\n",
      "|  Isabela Martins|      Salvador|       BMW|   320i|150000.0|\n",
      "|      João Santos|        Recife|      Audi|     A3|120000.0|\n",
      "|     Karina Rocha|        Manaus|  Mercedes|   C180|180000.0|\n",
      "|Leonardo Ferreira|     São Paulo| Chevrolet|  Cruze| 95000.0|\n",
      "|    Mariana Souza|Belo Horizonte|      Ford|     Ka| 40000.0|\n",
      "|Nathalia Teixeira|      Curitiba|   Hyundai| Tucson|100000.0|\n",
      "|   Otávio Moreira|  Porto Alegre|    Toyota|  Hilux|190000.0|\n",
      "| Patrícia Cardoso|     Fortaleza|      Jeep|Compass|150000.0|\n",
      "|  Ricardo Barbosa| Florianópolis|      Fiat|    Uno| 35000.0|\n",
      "|      Sofia Gomes|      Brasília|     Honda|    Fit| 80000.0|\n",
      "|     Thiago Alves|      Salvador|Volkswagen|   Polo| 85000.0|\n",
      "+-----------------+--------------+----------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_date\n",
    "import os\n",
    "\n",
    "# Define o caminho do diretório da raiz do projeto\n",
    "project_root = os.path.abspath(os.getcwd())\n",
    "warehouse_path = os.path.join(project_root, 'data_aula')\n",
    "\n",
    "# Inicializando a sessão do Spark com configurações do Hive\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Iceberg Example\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog.type\", \"hadoop\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog.warehouse\",warehouse_path) \\\n",
    "    .config(\"datanucleus.schema.autoCreateTables\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "# Criando a tabela de clientes\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE spark_catalog.default.clientes (\n",
    "        cd_cliente BIGINT,\n",
    "        nome STRING,\n",
    "        idade INT,\n",
    "        cidade STRING,\n",
    "        email STRING,\n",
    "        data_nascimento DATE\n",
    "    ) USING iceberg\n",
    "\"\"\")\n",
    "\n",
    "# Criando a tabela de carros com a chave estrangeira cd_cliente\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE spark_catalog.default.carros (\n",
    "        id BIGINT,\n",
    "        cd_cliente BIGINT,\n",
    "        marca STRING,\n",
    "        modelo STRING,\n",
    "        ano INT,\n",
    "        preco DOUBLE,\n",
    "        quilometragem BIGINT,\n",
    "        cor STRING,\n",
    "        tipo_combustivel STRING,\n",
    "        cambio STRING\n",
    "    ) USING iceberg\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# Inserindo dados de clientes\n",
    "dados_clientes = [\n",
    "    (1, \"Ana Silva\", 35, \"São Paulo\", \"ana.silva@gmail.com\", \"1989-02-10\"),\n",
    "    (2, \"Bruno Souza\", 40, \"Rio de Janeiro\", \"bruno.souza@gmail.com\", \"1984-06-21\"),\n",
    "    (3, \"Carlos Pereira\", 29, \"Belo Horizonte\", \"carlos.pereira@yahoo.com\", \"1995-03-14\"),\n",
    "    (4, \"Daniela Costa\", 25, \"Curitiba\", \"daniela.costa@outlook.com\", \"1999-09-07\"),\n",
    "    (5, \"Eduardo Oliveira\", 45, \"Porto Alegre\", \"eduardo.oliveira@gmail.com\", \"1979-12-30\"),\n",
    "    (6, \"Fernanda Lima\", 32, \"Fortaleza\", \"fernanda.lima@gmail.com\", \"1992-08-25\"),\n",
    "    (7, \"Gabriel Mendes\", 38, \"Florianópolis\", \"gabriel.mendes@gmail.com\", \"1986-10-15\"),\n",
    "    (8, \"Helena Ribeiro\", 28, \"Brasília\", \"helena.ribeiro@gmail.com\", \"1996-04-03\"),\n",
    "    (9, \"Isabela Martins\", 30, \"Salvador\", \"isabela.martins@gmail.com\", \"1994-01-18\"),\n",
    "    (10, \"João Santos\", 27, \"Recife\", \"joao.santos@gmail.com\", \"1997-11-22\"),\n",
    "    (11, \"Karina Rocha\", 36, \"Manaus\", \"karina.rocha@gmail.com\", \"1988-05-09\"),\n",
    "    (12, \"Leonardo Ferreira\", 41, \"São Paulo\", \"leonardo.ferreira@gmail.com\", \"1983-07-04\"),\n",
    "    (13, \"Mariana Souza\", 33, \"Belo Horizonte\", \"mariana.souza@gmail.com\", \"1991-12-15\"),\n",
    "    (14, \"Nathalia Teixeira\", 39, \"Curitiba\", \"nathalia.teixeira@gmail.com\", \"1985-09-12\"),\n",
    "    (15, \"Otávio Moreira\", 46, \"Porto Alegre\", \"otavio.moreira@gmail.com\", \"1978-02-28\"),\n",
    "    (16, \"Patrícia Cardoso\", 31, \"Fortaleza\", \"patricia.cardoso@gmail.com\", \"1993-06-19\"),\n",
    "    (17, \"Ricardo Barbosa\", 34, \"Florianópolis\", \"ricardo.barbosa@gmail.com\", \"1990-10-23\"),\n",
    "    (18, \"Sofia Gomes\", 26, \"Brasília\", \"sofia.gomes@gmail.com\", \"1998-04-13\"),\n",
    "    (19, \"Thiago Alves\", 42, \"Salvador\", \"thiago.alves@gmail.com\", \"1982-11-01\"),\n",
    "    (20, \"Vanessa Duarte\", 29, \"Recife\", \"vanessa.duarte@gmail.com\", \"1995-07-29\")\n",
    "]\n",
    "\n",
    "# Criando o DataFrame para clientes\n",
    "df_clientes = spark.createDataFrame(dados_clientes, [\"cd_cliente\", \"nome\", \"idade\", \"cidade\", \"email\", \"data_nascimento\"])\n",
    "\n",
    "# Convertendo a coluna 'data_nascimento' para o tipo 'date'\n",
    "df_clientes = df_clientes.withColumn(\"data_nascimento\", to_date(df_clientes[\"data_nascimento\"], \"yyyy-MM-dd\"))\n",
    "\n",
    "# Gravando os dados na tabela Iceberg 'clientes'\n",
    "df_clientes.writeTo(\"spark_catalog.default.clientes\").append()\n",
    "\n",
    "# Inserindo dados de carros, vinculando com clientes\n",
    "dados_carros = [\n",
    "    (1, 1, \"Toyota\", \"Corolla\", 2020, 75000.00, 15000, \"Prata\", \"Gasolina\", \"Automático\"),\n",
    "    (2, 1, \"Honda\", \"Civic\", 2019, 72000.00, 20000, \"Preto\", \"Flex\", \"Manual\"),\n",
    "    (3, 2, \"Ford\", \"Fiesta\", 2018, 55000.00, 30000, \"Branco\", \"Gasolina\", \"Automático\"),\n",
    "    (4, 3, \"Chevrolet\", \"Onix\", 2021, 68000.00, 5000, \"Vermelho\", \"Flex\", \"Automático\"),\n",
    "    (5, 4, \"Volkswagen\", \"Golf\", 2017, 90000.00, 40000, \"Azul\", \"Gasolina\", \"Manual\"),\n",
    "    (6, 5, \"Renault\", \"Sandero\", 2022, 62000.00, 1000, \"Cinza\", \"Flex\", \"Automático\"),\n",
    "    (7, 6, \"Hyundai\", \"HB20\", 2019, 69000.00, 12000, \"Prata\", \"Gasolina\", \"Automático\"),\n",
    "    (8, 7, \"Nissan\", \"Sentra\", 2020, 83000.00, 18000, \"Preto\", \"Gasolina\", \"Manual\"),\n",
    "    (9, 8, \"Fiat\", \"Argo\", 2021, 70000.00, 8000, \"Vermelho\", \"Flex\", \"Automático\"),\n",
    "    (10, 9, \"BMW\", \"320i\", 2020, 150000.00, 22000, \"Branco\", \"Gasolina\", \"Automático\"),\n",
    "    (11, 10, \"Audi\", \"A3\", 2021, 120000.00, 9000, \"Cinza\", \"Gasolina\", \"Automático\"),\n",
    "    (12, 11, \"Mercedes\", \"C180\", 2020, 180000.00, 15000, \"Preto\", \"Gasolina\", \"Automático\"),\n",
    "    (13, 12, \"Chevrolet\", \"Cruze\", 2019, 95000.00, 17000, \"Branco\", \"Flex\", \"Automático\"),\n",
    "    (14, 13, \"Ford\", \"Ka\", 2018, 40000.00, 35000, \"Vermelho\", \"Gasolina\", \"Manual\"),\n",
    "    (15, 14, \"Hyundai\", \"Tucson\", 2020, 100000.00, 18000, \"Preto\", \"Gasolina\", \"Automático\"),\n",
    "    (16, 15, \"Toyota\", \"Hilux\", 2019, 190000.00, 25000, \"Prata\", \"Diesel\", \"Automático\"),\n",
    "    (17, 16, \"Jeep\", \"Compass\", 2021, 150000.00, 10000, \"Branco\", \"Diesel\", \"Automático\"),\n",
    "    (18, 17, \"Fiat\", \"Uno\", 2017, 35000.00, 45000, \"Cinza\", \"Flex\", \"Manual\"),\n",
    "    (19, 18, \"Honda\", \"Fit\", 2018, 80000.00, 23000, \"Preto\", \"Gasolina\", \"Automático\"),\n",
    "    (20, 19, \"Volkswagen\", \"Polo\", 2021, 85000.00, 12000, \"Vermelho\", \"Flex\", \"Automático\"),\n",
    "    (21, 20, \"Renault\", \"Duster\", 2022, 90000.00, 5000, \"Azul\", \"Gasolina\", \"Automático\"),\n",
    "    (22, 1, \"Fiat\", \"Strada\", 2020, 65000.00, 20000, \"Branco\", \"Diesel\", \"Manual\"),\n",
    "    (23, 2, \"Chevrolet\", \"S10\", 2021, 180000.00, 8000, \"Prata\", \"Diesel\", \"Automático\"),\n",
    "    (24, 3, \"Volkswagen\", \"Jetta\", 2020, 125000.00, 13000, \"Preto\", \"Gasolina\", \"Automático\"),\n",
    "    (25, 4, \"Honda\", \"HR-V\", 2019, 90000.00, 24000, \"Cinza\", \"Gasolina\", \"Automático\"),\n",
    "    (26, 5, \"Hyundai\", \"Creta\", 2021, 120000.00, 7000, \"Branco\", \"Flex\", \"Automático\"),\n",
    "    (27, 6, \"Toyota\", \"Yaris\", 2020, 70000.00, 15000, \"Prata\", \"Flex\", \"Automático\"),\n",
    "    (28, 7, \"Ford\", \"Ranger\", 2019, 150000.00, 30000, \"Vermelho\", \"Diesel\", \"Automático\"),\n",
    "    (29, 8, \"Chevrolet\", \"Spin\", 2021, 85000.00, 10000, \"Preto\", \"Flex\", \"Manual\"),\n",
    "    (30, 9, \"BMW\", \"X1\", 2020, 180000.00, 21000, \"Azul\", \"Gasolina\", \"Automático\"),\n",
    "    (31, 10, \"Audi\", \"Q3\", 2021, 210000.00, 12000, \"Cinza\", \"Gasolina\", \"Automático\"),\n",
    "    (32, 11, \"Mercedes\", \"GLA\", 2020, 230000.00, 8000, \"Preto\", \"Gasolina\", \"Automático\"),\n",
    "    (33, 12, \"Chevrolet\", \"Tracker\", 2021, 95000.00, 5000, \"Branco\", \"Flex\", \"Automático\"),\n",
    "    (34, 13, \"Volkswagen\", \"T-Cross\", 2020, 115000.00, 11000, \"Prata\", \"Flex\", \"Automático\"),\n",
    "    (35, 14, \"Hyundai\", \"Santa Fe\", 2019, 150000.00, 17000, \"Preto\", \"Gasolina\", \"Automático\"),\n",
    "    (36, 15, \"Jeep\", \"Renegade\", 2021, 120000.00, 6000, \"Vermelho\", \"Diesel\", \"Automático\"),\n",
    "    (37, 16, \"Renault\", \"Captur\", 2020, 90000.00, 13000, \"Branco\", \"Flex\", \"Automático\"),\n",
    "    (38, 17, \"Fiat\", \"Mobi\", 2018, 40000.00, 20000, \"Cinza\", \"Flex\", \"Manual\"),\n",
    "    (39, 18, \"Honda\", \"City\", 2020, 90000.00, 22000, \"Prata\", \"Gasolina\", \"Automático\"),\n",
    "    (40, 19, \"Ford\", \"EcoSport\", 2021, 85000.00, 9000, \"Preto\", \"Flex\", \"Automático\"),\n",
    "    (41, 20, \"Volkswagen\", \"Virtus\", 2021, 95000.00, 8000, \"Azul\", \"Flex\", \"Automático\"),\n",
    "    (42, 1, \"Fiat\", \"Toro\", 2020, 130000.00, 12000, \"Vermelho\", \"Diesel\", \"Automático\"),\n",
    "    (43, 2, \"Chevrolet\", \"Onix Plus\", 2021, 75000.00, 3000, \"Prata\", \"Flex\", \"Automático\"),\n",
    "    (44, 3, \"Volkswagen\", \"Amarok\", 2020, 170000.00, 14000, \"Preto\", \"Diesel\", \"Automático\"),\n",
    "    (45, 4, \"Honda\", \"Civic\", 2019, 80000.00, 16000, \"Branco\", \"Gasolina\", \"Automático\"),\n",
    "    (46, 5, \"Hyundai\", \"i30\", 2021, 85000.00, 4000, \"Preto\", \"Gasolina\", \"Automático\"),\n",
    "    (47, 6, \"Toyota\", \"Etios\", 2019, 60000.00, 18000, \"Prata\", \"Flex\", \"Manual\"),\n",
    "    (48, 7, \"Ford\", \"Mustang\", 2020, 300000.00, 7000, \"Vermelho\", \"Gasolina\", \"Automático\"),\n",
    "    (49, 8, \"Chevrolet\", \"Celta\", 2017, 30000.00, 60000, \"Branco\", \"Flex\", \"Manual\"),\n",
    "    (50, 9, \"BMW\", \"X5\", 2021, 350000.00, 5000, \"Preto\", \"Gasolina\", \"Automático\")\n",
    "]\n",
    "\n",
    "# Criando o DataFrame para carros\n",
    "df_carros = spark.createDataFrame(dados_carros, [\"id\", \"cd_cliente\", \"marca\", \"modelo\", \"ano\", \"preco\", \"quilometragem\", \"cor\", \"tipo_combustivel\", \"cambio\"])\n",
    "\n",
    "# Gravando os dados na tabela Iceberg 'carros'\n",
    "df_carros.writeTo(\"spark_catalog.default.carros\").append()\n",
    "\n",
    "# Fazendo uma junção entre clientes e carros\n",
    "spark.sql(\"\"\"\n",
    "    SELECT c.nome, c.cidade, a.marca, a.modelo, a.preco\n",
    "    FROM spark_catalog.default.carros a\n",
    "    JOIN spark_catalog.default.clientes c ON a.cd_cliente = c.cd_cliente\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41feda5",
   "metadata": {},
   "source": [
    "#INCLUSAO DE CARRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d2451e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+-------+----+--------+-------------+--------+----------------+----------+\n",
      "| id|cd_cliente|     marca| modelo| ano|   preco|quilometragem|     cor|tipo_combustivel|    cambio|\n",
      "+---+----------+----------+-------+----+--------+-------------+--------+----------------+----------+\n",
      "|  1|         1|    Toyota|Corolla|2020| 75000.0|        15000|   Prata|        Gasolina|Automático|\n",
      "|  2|         1|     Honda|  Civic|2019| 72000.0|        20000|   Preto|            Flex|    Manual|\n",
      "|  3|         2|      Ford| Fiesta|2018| 55000.0|        30000|  Branco|        Gasolina|Automático|\n",
      "|  4|         3| Chevrolet|   Onix|2021| 68000.0|         5000|Vermelho|            Flex|Automático|\n",
      "|  5|         4|Volkswagen|   Golf|2017| 90000.0|        40000|    Azul|        Gasolina|    Manual|\n",
      "|  6|         5|   Renault|Sandero|2022| 62000.0|         1000|   Cinza|            Flex|Automático|\n",
      "|  7|         6|   Hyundai|   HB20|2019| 69000.0|        12000|   Prata|        Gasolina|Automático|\n",
      "|  8|         7|    Nissan| Sentra|2020| 83000.0|        18000|   Preto|        Gasolina|    Manual|\n",
      "|  9|         8|      Fiat|   Argo|2021| 70000.0|         8000|Vermelho|            Flex|Automático|\n",
      "| 10|         9|       BMW|   320i|2020|150000.0|        22000|  Branco|        Gasolina|Automático|\n",
      "| 11|        10|      Audi|     A3|2021|120000.0|         9000|   Cinza|        Gasolina|Automático|\n",
      "| 12|        11|  Mercedes|   C180|2020|180000.0|        15000|   Preto|        Gasolina|Automático|\n",
      "| 13|        12| Chevrolet|  Cruze|2019| 95000.0|        17000|  Branco|            Flex|Automático|\n",
      "| 14|        13|      Ford|     Ka|2018| 40000.0|        35000|Vermelho|        Gasolina|    Manual|\n",
      "| 15|        14|   Hyundai| Tucson|2020|100000.0|        18000|   Preto|        Gasolina|Automático|\n",
      "| 16|        15|    Toyota|  Hilux|2019|190000.0|        25000|   Prata|          Diesel|Automático|\n",
      "| 17|        16|      Jeep|Compass|2021|150000.0|        10000|  Branco|          Diesel|Automático|\n",
      "| 18|        17|      Fiat|    Uno|2017| 35000.0|        45000|   Cinza|            Flex|    Manual|\n",
      "| 19|        18|     Honda|    Fit|2018| 80000.0|        23000|   Preto|        Gasolina|Automático|\n",
      "| 20|        19|Volkswagen|   Polo|2021| 85000.0|        12000|Vermelho|            Flex|Automático|\n",
      "+---+----------+----------+-------+----+--------+-------------+--------+----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Novos dados de carros para incluir\n",
    "novos_dados_carros = [\n",
    "    (51, 1, \"Toyota\", \"Prius\", 2022, 90000.00, 5000, \"Branco\", \"Híbrido\", \"Automático\"),\n",
    "    (52, 2, \"Tesla\", \"Model 3\", 2023, 250000.00, 2000, \"Preto\", \"Elétrico\", \"Automático\")\n",
    "]\n",
    "\n",
    "# Criando DataFrame dos novos carros\n",
    "df_novos_carros = spark.createDataFrame(novos_dados_carros, [\"id\", \"cd_cliente\", \"marca\", \"modelo\", \"ano\", \"preco\", \"quilometragem\", \"cor\", \"tipo_combustivel\", \"cambio\"])\n",
    "\n",
    "# Incluindo os novos registros na tabela 'carros'\n",
    "df_novos_carros.writeTo(\"spark_catalog.default.carros\").append()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM spark_catalog.default.carros a\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4802f8",
   "metadata": {},
   "source": [
    "#ALTERAR TABELA DE CARROS\n",
    "\n",
    "No Iceberg, nao existe um metodo de UPDATE como nos bancos tradicionais, precisando entao fazer o comando merge.\n",
    "\n",
    "Outro exemplo de alteracao, seria sobrescrever os dados desejados da maneira abaixo:\n",
    "\n",
    "# Lendo os dados da tabela 'carros'\n",
    "df_carros = spark.table(\"spark_catalog.default.carros\")\n",
    "\n",
    "# Atualizando o preço do carro com 'id' 51\n",
    "df_carros_atualizado = df_carros.withColumn(\n",
    "    \"preco\", \n",
    "    when(df_carros.id == 51, 95000.00).otherwise(df_carros.preco)\n",
    ")\n",
    "\n",
    "# Sobrescrevendo a tabela com os dados atualizados\n",
    "df_carros_atualizado.writeTo(\"spark_catalog.default.carros\").overwrite()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d0f73ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------+------+----+-------+-------------+------+----------------+----------+\n",
      "| id|cd_cliente| marca|modelo| ano|  preco|quilometragem|   cor|tipo_combustivel|    cambio|\n",
      "+---+----------+------+------+----+-------+-------------+------+----------------+----------+\n",
      "| 51|         1|Toyota| Prius|2022|90000.0|         5000|Branco|         Híbrido|Automático|\n",
      "+---+----------+------+------+----+-------+-------------+------+----------------+----------+\n",
      "\n"
     ]
    },
    {
     "ename": "UnsupportedOperationException",
     "evalue": "MERGE INTO TABLE is not supported temporarily.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnsupportedOperationException\u001b[0m             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124m    SELECT * FROM spark_catalog.default.carros a where a.id = 51\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m----> 5\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43m    MERGE INTO spark_catalog.default.carros AS target\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43m    USING (SELECT 51 AS id, 95000.00 AS novo_preco) AS updates\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43m    ON target.id = updates.id\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;43m    WHEN MATCHED THEN UPDATE SET target.preco = updates.novo_preco\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124m    SELECT * FROM spark_catalog.default.carros a where a.id = 51\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pyspark/sql/session.py:1631\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m         litArgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoArray(\n\u001b[1;32m   1629\u001b[0m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[1;32m   1630\u001b[0m         )\n\u001b[0;32m-> 1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mUnsupportedOperationException\u001b[0m: MERGE INTO TABLE is not supported temporarily."
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM spark_catalog.default.carros a where a.id = 51\n",
    "\"\"\").show()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    MERGE INTO spark_catalog.default.carros AS target\n",
    "    USING (SELECT 51 AS id, 95000.00 AS novo_preco) AS updates\n",
    "    ON target.id = updates.id\n",
    "    WHEN MATCHED THEN UPDATE SET target.preco = updates.novo_preco\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM spark_catalog.default.carros a where a.id = 51\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c3b930",
   "metadata": {},
   "source": [
    "#DELECAO DE CARROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64b12e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deletando o carro com 'id' 52\n",
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM spark_catalog.default.carros a\n",
    "\"\"\").show()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    DELETE FROM spark_catalog.default.carros\n",
    "    WHERE id = 52\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM spark_catalog.default.carros a\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42dbf83",
   "metadata": {},
   "source": [
    "#INCLUSAO DE CLIENTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b361ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de novos clientes\n",
    "novos_dados_clientes = [\n",
    "    (21, \"Pedro Nunes\", 37, \"São Paulo\", \"pedro.nunes@gmail.com\", \"1987-07-19\"),\n",
    "    (22, \"Maria Clara\", 28, \"Rio de Janeiro\", \"maria.clara@gmail.com\", \"1996-11-22\")\n",
    "]\n",
    "\n",
    "# Criando DataFrame dos novos clientes\n",
    "df_novos_clientes = spark.createDataFrame(novos_dados_clientes, [\"cd_cliente\", \"nome\", \"idade\", \"cidade\", \"email\", \"data_nascimento\"])\n",
    "\n",
    "# Convertendo a coluna 'data_nascimento' para o tipo 'date'\n",
    "df_novos_clientes = df_novos_clientes.withColumn(\"data_nascimento\", to_date(df_novos_clientes[\"data_nascimento\"], \"yyyy-MM-dd\"))\n",
    "\n",
    "# Incluindo os novos registros na tabela 'clientes'\n",
    "df_novos_clientes.writeTo(\"spark_catalog.default.clientes\").append()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM spark_catalog.default.clientes\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a4f162",
   "metadata": {},
   "source": [
    "#ALTERACAO DE CLIENTE\n",
    "\n",
    "No Iceberg, nao existe um metodo de UPDATE como nos bancos tradicionais, precisando entao fazer o comando merge.\n",
    "\n",
    "Outro exemplo de alteracao, seria sobrescrever os dados desejados da maneira abaixo:\n",
    "\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Lendo os dados da tabela 'clientes'\n",
    "df_clientes = spark.table(\"spark_catalog.default.clientes\")\n",
    "\n",
    "# Atualizando o email do cliente com 'cd_cliente' 21\n",
    "df_clientes_atualizado = df_clientes.withColumn(\n",
    "    \"email\", \n",
    "    when(df_clientes.cd_cliente == 21, \"pedro.nunes@novodominio.com\").otherwise(df_clientes.email)\n",
    ")\n",
    "\n",
    "# Sobrescrevendo a tabela com os dados atualizados\n",
    "df_clientes_atualizado.writeTo(\"spark_catalog.default.clientes\").overwrite()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2b10a33",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnsupportedOperationException",
     "evalue": "MERGE INTO TABLE is not supported temporarily.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnsupportedOperationException\u001b[0m             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Atualizando o email do cliente com 'cd_cliente' 21\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43m    MERGE INTO spark_catalog.default.clientes AS target\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43m    USING (SELECT 21 AS cd_cliente, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpedro.nunes@novodominio.com\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m AS novo_email) AS updates\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43m    ON target.cd_cliente = updates.cd_cliente\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43m    WHEN MATCHED THEN UPDATE SET target.email = updates.novo_email\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pyspark/sql/session.py:1631\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m         litArgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoArray(\n\u001b[1;32m   1629\u001b[0m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[1;32m   1630\u001b[0m         )\n\u001b[0;32m-> 1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mUnsupportedOperationException\u001b[0m: MERGE INTO TABLE is not supported temporarily."
     ]
    }
   ],
   "source": [
    "# Atualizando o email do cliente com 'cd_cliente' 21\n",
    "spark.sql(\"\"\"\n",
    "    MERGE INTO spark_catalog.default.clientes AS target\n",
    "    USING (SELECT 21 AS cd_cliente, 'pedro.nunes@novodominio.com' AS novo_email) AS updates\n",
    "    ON target.cd_cliente = updates.cd_cliente\n",
    "    WHEN MATCHED THEN UPDATE SET target.email = updates.novo_email\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fb1347",
   "metadata": {},
   "source": [
    "#DELECAO DE CLIENTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d76a8ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM spark_catalog.default.clientes\n",
    "\"\"\").show()\n",
    "\n",
    "\n",
    "# Deletando o cliente com 'cd_cliente' 22\n",
    "spark.sql(\"\"\"\n",
    "    DELETE FROM spark_catalog.default.clientes\n",
    "    WHERE cd_cliente = 22\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM spark_catalog.default.clientes\n",
    "\"\"\").show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
